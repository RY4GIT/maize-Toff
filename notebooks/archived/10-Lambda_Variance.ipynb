{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Variance to $\\lambda$ Values\n",
    "\n",
    "This notebook explores the impact of letting $\\lambda$ values be sampled from a normal distribution instead of just using a constant value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from farm.climate import make_climate_parameters, check_exponential, Climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.057239057239057235, 0.06666666666666667, 0.03636363636363636, 0.04545454545454546, 0.06060606060606061, 0.045454545454545456, 0.06363636363636364, 0.07878787878787881, 0.1696969696969697, 0.2, 0.26562499999999994, 0.32812500000000006, 0.35625, 0.384375, 0.20312499999999994, 0.140625, 0.140625, 0.14062499999999997, 0.15625, 0.17187499999999994, 0.190625, 0.15312499999999998, 0.14062499999999997, 0.13750000000000004, 0.15625, 0.11562500000000002, 0.11562500000000003, 0.10312500000000002, 0.1774193548387097, 0.264516129032258, 0.27419354838709675, 0.2806451612903226, 0.21612903225806449, 0.17741935483870963, 0.11290322580645161, 0.08064516129032258, 0.04608294930875576] [0.1499002037396287, 0.13385315336840842, 0.06990252954195317, 0.0904534033733291, 0.10289373747765805, 0.11205720941473683, 0.13420642174040567, 0.12439246298906075, 0.18789100644530674, 0.21937410968480306, 0.1993689641618468, 0.24261262765316685, 0.21543279769473506, 0.20652169299475384, 0.15551034609290626, 0.1775448603011499, 0.1521022046032249, 0.19486864889607217, 0.203100960115899, 0.15909902576697318, 0.18203043878747668, 0.16458035590065753, 0.13645127926444378, 0.17551766752353798, 0.131829557603993, 0.12471742253538987, 0.14392958627902608, 0.12309025013143551, 0.19443881200239635, 0.18174778695906077, 0.2175128225116608, 0.19734800875392633, 0.205096358156434, 0.20446626032894333, 0.1727077212786021, 0.14004607536738203, 0.08516922904651784]\n"
     ]
    }
   ],
   "source": [
    "#%% Climate Class Definition\n",
    "from math import exp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import exponential, uniform\n",
    "from dateutil.relativedelta import *\n",
    "import scipy.stats as st\n",
    "\n",
    "default_climate = {\n",
    "    'alpha_r': [10.0] * 12,\n",
    "    'lambda_r': [0.25] * 12,\n",
    "    'ET_max': 6.5\n",
    "}\n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "datetimes = np.arange(\n",
    "    datetime(2018,1,1), datetime(2019,1,1), timedelta(days=1)\n",
    "    ).astype(datetime)\n",
    "\n",
    "month_value_by_day = np.array([datetime.month for datetime in datetimes])\n",
    "week_value_by_day = np.array([datetime.isocalendar()[1] for datetime in datetimes])\n",
    "dekad_value_by_day = np.array([(datetime_.timetuple().tm_yday - 1)//10+1 for datetime_ in datetimes])\n",
    "# TODO Add semi_month_value_by_day if using \n",
    "\n",
    "# def make_climate_parameters(\n",
    "station='OL JOGI FARM'\n",
    "data_file=\"../data/CETRAD/CETRAD_rainfall.csv\"\n",
    "year_min=30\n",
    "interval='dekad'\n",
    "do_std=True\n",
    "\n",
    "\"\"\" Defines function that takes a rainfall station time series and returns alpha and lambda values by \n",
    "a certain interval between week (7-days), dekad (10-days), semi-monthly (twice per month) or monthly.\n",
    "\n",
    "    Usage:\n",
    "\n",
    "        make_climate_parameters(\n",
    "            station='OL JOGI FARM', \n",
    "            data_file=\"data/CETRAD/CETRAD_rainfall.csv\",\n",
    "            year_min= 30,\n",
    "            interval='dekad' \n",
    "        )\n",
    "\n",
    "    Default values:\n",
    "        station = 'OL JOGI FARM' [string] # Rainfall Climatology for Laikipia \n",
    "        data_file = \"data/CETRAD/CETRAD_rainfall.csv\" # Path to file\n",
    "        year_min = 30 # Minimum number of years required in timeseries\n",
    "        interval = 'dekad' # Interval to calculate alphas andlambdas\n",
    "\n",
    "            returns alpha_values, lambda_values\n",
    "\"\"\"\n",
    "# Prepare the CETRAD dataset.\n",
    "year_min = year_min # minimum number of years to consider for a valid climate record.\n",
    "\n",
    "df = pd.read_csv(data_file)  # Read in the raw csv data.\n",
    "\n",
    "# Step 1. Convert text strings into datetime objects.\n",
    "format = '%m/%d/%y' # Column RDate has data in M/D/YY\n",
    "df['Datetime']=pd.to_datetime(df['RDate'], format=format) # Create a new column of datetime objects using RDate.\n",
    "\n",
    "# 2. Step 2. Convert future dates inferred during the conversion back into 20th century dates.\n",
    "# Python is a future-looking programming language, and assumes that 1/1/34 is Jan 1, 2034.\n",
    "# We can fix this by finding all the dates in the future (dt > datetime.now()) and removing 100 years from\n",
    "# their value. This requires using the relativedelta function, which handles weird stuff like leap years.\n",
    "df['Datetime'] = df['Datetime'].map(lambda dt: dt+relativedelta(years=-100) if dt > datetime.now() else dt)\n",
    "\n",
    "# Step 3. Extract the Year and Month from the Datetime to make aggregation easier.\n",
    "df['Year'] = [dt.year for dt in df['Datetime']]\n",
    "df['Month'] = [dt.month for dt in df['Datetime']]\n",
    "df['Week'] = [dt.week for dt in df['Datetime']]\n",
    "df['Semi_Month'] = (df['Datetime'].dt.day\n",
    "                      .gt((df['Datetime']+pd.tseries.offsets.MonthEnd()).dt.day//2) \n",
    "                      + df['Month']*2 -1)\n",
    "df['Dekad'] = df['Datetime'].dt.dayofyear//10+1\n",
    "\n",
    "n_years = len(df['Year'].unique())\n",
    "\n",
    "# Check to make sure we have enough data for fitting and parameter estimation.\n",
    "if n_years < year_min:\n",
    "    print(\"WARNING! Station record for {station} has only {n_years} years.\".format(\n",
    "        station=station,\n",
    "        n_years=n_years))\n",
    "\n",
    "# Step 4. Use the Datetime values as the index for this dataframe.\n",
    "df = df.set_index(pd.DatetimeIndex(df['Datetime']))  # Set the Datetime column as the dataframe index\n",
    "\n",
    "# Step 5.  Delete the old RDate column, which we no longer need. \n",
    "# We will keep the Datetime column, in case we need it later.\n",
    "df = df.drop(['RDate'], axis=1)\n",
    "\n",
    "columns = [station] + ['Year', 'Month', 'Week', 'Dekad', 'Semi_Month','Datetime']\n",
    "rainfall = df[columns]\n",
    "\n",
    "# First, find all the rows in the data where it rained and group by month.\n",
    "rain_days = rainfall.loc[rainfall[station] > 0]\n",
    "\n",
    "# Find all locations in the data where an observation was made.\n",
    "all_days = rainfall.loc[rainfall[station] >= 0] \n",
    "\n",
    "# Find just the rainfall amounts on days that it rained.\n",
    "data = rainfall.loc[rainfall[station] > 0][station]\n",
    "\n",
    "# Fit the daily rainfall amounts to an exponential distribution.\n",
    "check_exponential(data)\n",
    "\n",
    "if interval == 'month':\n",
    "    # Determine the Monthly values of alpha and lambda from the station data:\n",
    "    s = pd.DataFrame(\n",
    "        rain_days.groupby(['Month', 'Year'])[station].count().unstack(fill_value=0).stack() /\n",
    "        all_days.groupby(['Month', 'Year'])[station].count()\n",
    "    )[0]\n",
    "    df = pd.DataFrame(s).reset_index()\n",
    "    df.columns = ['Month', 'Year', 'Value']\n",
    "    avg_lambda_values = df.groupby('Month')['Value'].mean()\n",
    "    if do_std:\n",
    "        std_lambda_values = df.groupby('Month')['Value'].std()\n",
    "    else:\n",
    "        std_lambda_values = avg_lambda_values * 0\n",
    "    alpha_values = rain_days.groupby('Month')[station].mean()\n",
    "elif interval == 'dekad':\n",
    "    s = pd.DataFrame(\n",
    "        rain_days.groupby(['Dekad', 'Year'])[station].count().unstack(fill_value=0).stack() / \n",
    "        all_days.groupby(['Dekad', 'Year'])[station].count()\n",
    "    )[0]\n",
    "    df = pd.DataFrame(s).reset_index()\n",
    "    df.columns = ['Dekad', 'Year', 'Value']\n",
    "    avg_lambda_values = df.groupby('Dekad')['Value'].mean()\n",
    "    if do_std:\n",
    "        std_lambda_values = df.groupby('Dekad')['Value'].std()\n",
    "    else:\n",
    "        std_lambda_values = avg_lambda_values * 0\n",
    "    alpha_values = rain_days.groupby('Dekad')[station].mean()\n",
    "elif interval == 'semi_month':\n",
    "    s = pd.DataFrame(\n",
    "        rain_days.groupby(['Semi_Month', 'Year'])[station].count().unstack(fill_value=0).stack() / \n",
    "        all_days.groupby(['Semi_Month', 'Year'])[station].count()\n",
    "    )[0]\n",
    "    df = pd.DataFrame(s).reset_index()\n",
    "    df.columns = ['Semi_Month', 'Year', 'Value']\n",
    "    avg_lambda_values = df.groupby['Dekad']['Value'].mean()\n",
    "    if do_std:\n",
    "        std_lambda_values = df.groupby['Dekad']['Value'].std()\n",
    "    else:\n",
    "        std_lambda_values = avg_lambda_values * 0\n",
    "else:\n",
    "    raise(NotImplementedError)\n",
    "    \n",
    "print(avg_lambda_values.to_list(), std_lambda_values.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1082427469092115"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(scale=0.1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
